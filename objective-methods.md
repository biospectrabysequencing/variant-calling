## Objective and methods
*(Maximum 4 pages, including up to 5 references)*
1. _What is the expected outcome of this project? e.g. Hypothesis to be tested and/or Key question or Objective, and/or Capability or Platform that will be developed_
2. _Current situation – What do we already know? What are we already doing? Who else is working in this space within NZ or internationally?  If relevant, who are we currently working with in this area?_
3. _What is the novelty and/or stretch?_
4. _Outline of methods/approach (at least one page)_
5. _What data will be collected and how will it be analysed and managed to ensure it is available to others with an interest in this area?_
6. _What is the IP situation / freedom to operate?_
7. _Identify any risks in conducting the science and state how they will be managed._
8. _If relevant, state how this work will enhance or develop a collaboration. Name the external collaborators (key personnel, organisation, country) and state what capability or resources they are expected to contribute to the proposal and how that will be funded. Note if this is covered by an existing contract or MOU or if a new agreement is required._
9. _If relevant, note any new capability that will be developed, or any issues with respect to maintaining and/or enhancing existing skills that are addressed in the proposal._ 

###Point 1  -- Expected Outcome

An automated framework for assessing, appraising, comparing and contrasting existing pipelines and the analysis outputs they provide for input data as generated by researchers as well as the exemplar datasets \cite{Torkamaneh_16}.

_The above describes the 'thing' that we'll be making. The expected outcomes should be more than that. e.g. improved accuracy of genetic analyses based on better marker data -- extrapolate from here. --Rob_

We have three use cases to ensure we have the volume and variety of data to trail and stress the framework and ensure practical utility.

**David Chagne ??**

**Samantha Baldwin or Maren Wellenreuther ??**

### Point 2  -- Current Situation

We are running multiple pipelines to discover variants without being able to appraise the accuracy of the variant calls of each of the tools. Very often set operations on the outputs yield unexpected results. Scientists, rightly, have concern over the validity of such outputs and rely heavily on consensus from the multiple tools.

### Point 3 -- Novelty / Stretch

The work done within this proposal will provide the foundation in terms of software frameworks and skill sets necessary to generalise the methodology to other variant calling pipelines and workflows.

### Point 4 -- Outilne of methods (at least 1 page)

Multiple genomic read aligners, assemblers, and variant callers will be assessed on their performance using many sets of simulated read data. The data will be obtained by permutation from a “known-good” source, such as one of the human chromosomes. The controls will be sets of “perfect reads” generated as an idealization of the sequencing process, for the specified type, with a specific allele frequency. The idealized reads will then be permuted in a fashion that mimics both the introduction of sequencing errors as well as the introduction of sequencing biases and the incorporation of a range of allele frequencies. Each tool will be run on the sample data sets, and then the results evaluated using the appropriate standard criteria, including the ability to handle polyploid data correctly and efficiently.

Development external, using external system to facilitate transparency and accessibility of work with collaborators.

Development of Cloud capability.

### Point 5 -- Data

For the project we will use existing data that has been collected, or is planned to be, by the named researchers in the use cases.

#### Simulated Data

* Maybe Marcus and / or Charles can describe simulated data sets from various species of interest here.

#### Existing Data

* What PFR data could be used?
* Soybean data sets. Both WGS and GBS generated from the sames extraced DNAs (diploid, inbred) This is from the group @ Lavall in Canada
* Willow data. These are polyploids of varying levels. (I just requested the data from Larry Smart @ Cornell)
* We should look through the literature and contact groups that have published data sets that are interesting from the testing point of view.

#### New Data generated

* What would be good for PFR??
 
### Point 6 -- IP / FTO

There are no known IP restrictions. The bulk of the tools that we will be using / testing are released under Free / Open Source software licenses. The best practice in software development dictates that software integrating those components be licensed under a compatible license. This also follows the NZGOAL-SE framework and is regarded as best practice by the NZ central government \cite{NZGOAL-SE_2017}.

~~MOU with Elshire Group.~~ -- I'm in favour of putting all this under the NZOSS. Neutral ground and same rules for everyone... (Rob)

### Point 7 -- Risk Management

### Point 8 -- Collaboration

* The Elshire Group -- Coordination, Code Contributions, etc.
* Laval University -- Francois Belzile's Group(FastGBS pipeline, soybean data sets, analsysis tools)
* Cornell University -- Larry Smart (polyploid data sets)
* Yale -- Deren Eaton (pyRad / ipyRad)
* University of New Hampshire -- Iago Hale's Group (GBS-SNP-CROP pipeline)
* Possibly Canterbury -- Tammy Steeves group 

### Point 9 -- New Capability

*    An understanding of the strengths and limitations of various variant callers.
*    Increased power in application of marker technology.
*    Upskilled staff in regards to design, coding and deployment of cloud based reproducible workflows.
*    Flexibility to easily evaluate future variant calling pipelines.


